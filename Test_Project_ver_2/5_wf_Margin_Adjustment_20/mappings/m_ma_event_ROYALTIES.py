# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")


# COMMAND ----------
# DBTITLE 1, Shortcut_to_SEQ_MA_EVENT_ID


spark.sql(
  """CREATE TABLE IF NOT EXISTS Shortcut_to_SEQ_MA_EVENT_ID(NEXTVAL BIGINT,
CURRVAL BIGINT,
Increment_By Int);"""
)

spark.sql(
  """INSERT INTO Shortcut_to_SEQ_MA_EVENT_ID(NEXTVAL BIGINT,
CURRVAL BIGINT,
Increment_By Int) VALUES(2, 1, 1)"""
)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_MaRoyaltySKU_1


df_1 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  ProductId AS ProductId
FROM
  MaRoyaltySKU""")

df_1.createOrReplaceTempView("Shortcut_to_MaRoyaltySKU_1")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_MaRoyaltySKU_2


df_2 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  ProductId AS ProductId,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_MaRoyaltySKU_1""")

df_2.createOrReplaceTempView("SQ_Shortcut_to_MaRoyaltySKU_2")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_MaRoyaltyBrand_3


df_3 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  BrandCd AS BrandCd,
  SkuListInd AS SkuListInd,
  ContractStartDate AS ContractStartDate,
  ContractEndDate AS ContractEndDate,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyPct AS RoyaltyPct
FROM
  MaRoyaltyBrand""")

df_3.createOrReplaceTempView("Shortcut_to_MaRoyaltyBrand_3")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_MaRoyaltyBrand_4


df_4 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  BrandCd AS BrandCd,
  SkuListInd AS SkuListInd,
  ContractStartDate AS ContractStartDate,
  ContractEndDate AS ContractEndDate,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyPct AS RoyaltyPct,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_MaRoyaltyBrand_3""")

df_4.createOrReplaceTempView("SQ_Shortcut_to_MaRoyaltyBrand_4")

# COMMAND ----------
# DBTITLE 1, JNR_RoyaltyBrandIdNew_5


df_5 = spark.sql("""SELECT
  MASTER.RoyaltyBrandId AS RoyaltyBrandId1,
  MASTER.RoyaltyBrandDesc AS RoyaltyBrandDesc,
  MASTER.BrandCd AS BrandCd,
  MASTER.SkuListInd AS SkuListInd,
  MASTER.ContractStartDate AS ContractStartDate,
  MASTER.ContractEndDate AS ContractEndDate,
  MASTER.RoyaltyFormulaCd AS RoyaltyFormulaCd,
  MASTER.RoyaltyPct AS RoyaltyPct,
  DETAIL.RoyaltyBrandId AS RoyaltyBrandId,
  DETAIL.ProductId AS ProductId,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_MaRoyaltyBrand_4 MASTER
  LEFT JOIN SQ_Shortcut_to_MaRoyaltySKU_2 DETAIL ON MASTER.RoyaltyBrandId = DETAIL.RoyaltyBrandId""")

df_5.createOrReplaceTempView("JNR_RoyaltyBrandIdNew_5")

# COMMAND ----------
# DBTITLE 1, EXP_RoyaltyBrandNew_6


df_6 = spark.sql("""SELECT
  RoyaltyBrandId1 AS RoyaltyBrandId,
  ProductId AS ProductId,
  BrandCd AS BrandCd,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  (RoyaltyPct * 100) * -1 AS RoyaltyPct1,
  ContractStartDate AS ContractStartDate,
  ContractEndDate AS ContractEndDate,
  SkuListInd AS SkuListInd,
  1 AS Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_RoyaltyBrandIdNew_5""")

df_6.createOrReplaceTempView("EXP_RoyaltyBrandNew_6")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_EXT_DAYS_7


df_7 = spark.sql("""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  EXT_DAYS""")

df_7.createOrReplaceTempView("Shortcut_to_EXT_DAYS_7")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_EXT_DAYS_8


df_8 = spark.sql("""SELECT
  DAY_DT AS DAY_DT,
  FISCAL_MO AS FISCAL_MO,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_EXT_DAYS_7""")

df_8.createOrReplaceTempView("SQ_Shortcut_to_EXT_DAYS_8")

# COMMAND ----------
# DBTITLE 1, EXP_Ext_Days_9


df_9 = spark.sql("""SELECT
  DAY_DT AS DAY_DT,
  FISCAL_MO AS FISCAL_MO,
  1 AS Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_EXT_DAYS_8""")

df_9.createOrReplaceTempView("EXP_Ext_Days_9")

# COMMAND ----------
# DBTITLE 1, JNR_MaRoyalty_10


df_10 = spark.sql("""SELECT
  MASTER.RoyaltyBrandId AS RoyaltyBrandId,
  MASTER.ProductId AS ProductId,
  MASTER.BrandCd AS BrandCd,
  MASTER.RoyaltyFormulaCd AS RoyaltyFormulaCd,
  MASTER.RoyaltyBrandDesc AS RoyaltyBrandDesc,
  MASTER.RoyaltyPct1 AS RoyaltyPct1,
  MASTER.ContractStartDate AS ContractStartDate,
  MASTER.ContractEndDate AS ContractEndDate,
  MASTER.SkuListInd AS SkuListInd,
  MASTER.Flag AS Flag1,
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.FISCAL_MO AS FISCAL_MO,
  DETAIL.Flag AS Flag,
  nvl(
    MASTER.Monotonically_Increasing_Id,
    DETAIL.Monotonically_Increasing_Id
  ) AS Monotonically_Increasing_Id
FROM
  EXP_RoyaltyBrandNew_6 MASTER
  FULL OUTER JOIN EXP_Ext_Days_9 DETAIL ON MASTER.Flag = DETAIL.Flag""")

df_10.createOrReplaceTempView("JNR_MaRoyalty_10")

# COMMAND ----------
# DBTITLE 1, FIL_Date_11


df_11 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  ProductId AS ProductId,
  BrandCd AS BrandCd,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  RoyaltyPct1 AS RoyaltyPct1,
  ContractStartDate AS ContractStartDate,
  ContractEndDate AS ContractEndDate,
  SkuListInd AS SkuListInd,
  DAY_DT AS DAY_DT,
  FISCAL_MO AS FISCAL_MO,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_MaRoyalty_10
WHERE
  DAY_DT >= ContractStartDate
  AND DAY_DT <= ContractEndDate
  AND FISCAL_MO >= 201605
  AND FISCAL_MO <= 299999""")

df_11.createOrReplaceTempView("FIL_Date_11")

# COMMAND ----------
# DBTITLE 1, AGG_Day_Dt_12


df_12 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  MIN(DAY_DT) AS START_DT,
  MAX(DAY_DT) AS END_DT,
  ProductId AS ProductId,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  BrandCd AS BrandCd,
  SkuListInd AS SkuListInd,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyPct1 AS RoyaltyPct1,
  FISCAL_MO AS FISCAL_MO,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  FIL_Date_11
GROUP BY
  RoyaltyBrandId,
  ProductId,
  RoyaltyBrandDesc,
  BrandCd,
  SkuListInd,
  RoyaltyFormulaCd,
  RoyaltyPct1,
  FISCAL_MO""")

df_12.createOrReplaceTempView("AGG_Day_Dt_12")

# COMMAND ----------
# DBTITLE 1, EXP_PriductIdNew_13


df_13 = spark.sql("""SELECT
  RoyaltyBrandId AS RoyaltyBrandId,
  IFF(ISNULL(ProductId), 0, ProductId) AS PRODUCT_ID_JOIN,
  ProductId AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  RoyaltyBrandDesc AS RoyaltyBrandDesc,
  BrandCd AS BrandCd,
  SkuListInd AS SkuListInd,
  RoyaltyFormulaCd AS RoyaltyFormulaCd,
  RoyaltyPct1 AS RoyaltyPct1,
  FISCAL_MO AS FISCAL_MO,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGG_Day_Dt_12""")

df_13.createOrReplaceTempView("EXP_PriductIdNew_13")

# COMMAND ----------
# DBTITLE 1, LKP_EXT_DAYS_14


df_14 = spark.sql("""SELECT
  ED.DAY_DT AS DAY_DT,
  EP1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_PriductIdNew_13 EP1
  LEFT JOIN (
    SELECT
      DATEADD(day, 1, WEEK_DT) as DAY_DT
    FROM
      EXT_DAYS
    WHERE
      DAY_DT = DATEADD(dd, DATEDIFF(dd, 96, getdate()), 0)
  ) AS ED ON ED.DAY_DT < EP1.START_DT""")

df_14.createOrReplaceTempView("LKP_EXT_DAYS_14")

# COMMAND ----------
# DBTITLE 1, FIL_Having_15


df_15 = spark.sql("""SELECT
  LED1.DAY_DT AS DAY_DT,
  EP1.RoyaltyBrandId AS RoyaltyBrandId,
  EP1.START_DT AS START_DT,
  EP1.END_DT AS END_DT,
  EP1.PRODUCT_ID_JOIN AS PRODUCT_ID_JOIN,
  EP1.PRODUCT_ID AS PRODUCT_ID,
  EP1.RoyaltyBrandDesc AS RoyaltyBrandDesc,
  EP1.BrandCd AS BrandCd,
  EP1.RoyaltyFormulaCd AS RoyaltyFormulaCd,
  EP1.RoyaltyPct1 AS RoyaltyPct1,
  EP1.FISCAL_MO AS FISCAL_MO,
  EP1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_PriductIdNew_13 EP1
  INNER JOIN LKP_EXT_DAYS_14 LED1 ON EP1.Monotonically_Increasing_Id = LED1.Monotonically_Increasing_Id
WHERE
  NOT ISNULL(LED1.DAY_DT)""")

df_15.createOrReplaceTempView("FIL_Having_15")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_MA_EVENT1_16


df_16 = spark.sql("""SELECT
  MA_EVENT_ID AS MA_EVENT_ID,
  OFFER_ID AS OFFER_ID,
  SAP_DEPT_ID AS SAP_DEPT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  COUNTRY_CD AS COUNTRY_CD,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  LOCATION_ID AS LOCATION_ID,
  MOVEMENT_ID AS MOVEMENT_ID,
  VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
  GL_ACCT_NBR AS GL_ACCT_NBR,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  FROM_LOCATION_ID AS FROM_LOCATION_ID,
  SOURCE_VENDOR_ID AS SOURCE_VENDOR_ID,
  COMPANY_ID AS COMPANY_ID,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  EM_VENDOR_FUNDING_ID AS EM_VENDOR_FUNDING_ID,
  EM_COMMENT AS EM_COMMENT,
  EM_BILL_ALT_VENDOR_FLAG AS EM_BILL_ALT_VENDOR_FLAG,
  EM_ALT_VENDOR_ID AS EM_ALT_VENDOR_ID,
  EM_ALT_VENDOR_NAME AS EM_ALT_VENDOR_NAME,
  EM_ALT_VENDOR_COUNTRY_CD AS EM_ALT_VENDOR_COUNTRY_CD,
  EM_VENDOR_ID AS EM_VENDOR_ID,
  EM_VENDOR_NAME AS EM_VENDOR_NAME,
  EM_VENDOR_COUNTRY_CD AS EM_VENDOR_COUNTRY_CD,
  VENDOR_NAME_TXT AS VENDOR_NAME_TXT,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  MA_MAX_AMT AS MA_MAX_AMT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  MA_EVENT""")

df_16.createOrReplaceTempView("Shortcut_to_MA_EVENT1_16")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_MA_EVENT_17


df_17 = spark.sql("""SELECT
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_AMT AS MA_AMT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_MA_EVENT1_16""")

df_17.createOrReplaceTempView("SQ_Shortcut_to_MA_EVENT_17")

# COMMAND ----------
# DBTITLE 1, FIL_Royalty_18


df_18 = spark.sql("""SELECT
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  FISCAL_MO AS FISCAL_MO,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_AMT AS MA_AMT,
  MA_EVENT_ID AS MA_EVENT_ID,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_MA_EVENT_17
WHERE
  MA_EVENT_TYPE_ID = 10 --royalty
  AND FISCAL_MO >= 201604""")

df_18.createOrReplaceTempView("FIL_Royalty_18")

# COMMAND ----------
# DBTITLE 1, LKP_DAYS_19


df_19 = spark.sql("""SELECT
  D.WEEK_DT AS WEEK_DT,
  FR1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Royalty_18 FR1
  LEFT JOIN (
    SELECT
      (WEEK_DT + 1) AS WEEK_DT
    FROM
      DAYS
    WHERE
      DAY_DT = CURRENT_DATE - 96
  ) AS D ON D.WEEK_DT < FR1.START_DT""")

df_19.createOrReplaceTempView("LKP_DAYS_19")

# COMMAND ----------
# DBTITLE 1, FIL_START_DT_20


df_20 = spark.sql("""SELECT
  LD1.WEEK_DT AS WEEK_DT,
  FR1.ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  FR1.PRODUCT_ID AS PRODUCT_ID,
  FR1.START_DT AS START_DT,
  FR1.END_DT AS END_DT,
  FR1.FISCAL_MO AS FISCAL_MO,
  FR1.BRAND_CD AS BRAND_CD,
  FR1.MA_FORMULA_CD AS MA_FORMULA_CD,
  FR1.MA_EVENT_DESC AS MA_EVENT_DESC,
  FR1.MA_AMT AS MA_AMT,
  FR1.MA_EVENT_ID AS MA_EVENT_ID,
  FR1.UPDATE_DT AS UPDATE_DT,
  FR1.LOAD_DT AS LOAD_DT,
  FR1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Royalty_18 FR1
  INNER JOIN LKP_DAYS_19 LD1 ON FR1.Monotonically_Increasing_Id = LD1.Monotonically_Increasing_Id
WHERE
  NOT ISNULL(LD1.WEEK_DT)""")

df_20.createOrReplaceTempView("FIL_START_DT_20")

# COMMAND ----------
# DBTITLE 1, EXP_ProductId_21


df_21 = spark.sql("""SELECT
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  IFF(ISNULL(PRODUCT_ID), 0, PRODUCT_ID) AS PRODUCT_ID_JOIN,
  START_DT AS START_DT,
  END_DT AS END_DT,
  PRODUCT_ID AS PRODUCT_ID,
  FISCAL_MO AS FISCAL_MO,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_AMT AS MA_AMT,
  MA_EVENT_ID AS MA_EVENT_ID,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_START_DT_20""")

df_21.createOrReplaceTempView("EXP_ProductId_21")

# COMMAND ----------
# DBTITLE 1, JNR_All_22


df_22 = spark.sql("""SELECT
  DETAIL.ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  DETAIL.PRODUCT_ID_JOIN AS PRODUCT_ID_JOIN,
  DETAIL.START_DT AS START_DT,
  DETAIL.END_DT AS END_DT,
  DETAIL.PRODUCT_ID AS PRODUCT_ID,
  DETAIL.FISCAL_MO AS FISCAL_MO,
  DETAIL.BRAND_CD AS BRAND_CD,
  DETAIL.MA_FORMULA_CD AS MA_FORMULA_CD,
  DETAIL.MA_EVENT_DESC AS MA_EVENT_DESC,
  DETAIL.MA_AMT AS MA_AMT,
  DETAIL.MA_EVENT_ID AS MA_EVENT_ID,
  DETAIL.UPDATE_DT AS UPDATE_DT,
  DETAIL.LOAD_DT AS LOAD_DT,
  MASTER.RoyaltyBrandId AS ROYALTY_BRAND_ID_MTX,
  MASTER.PRODUCT_ID_JOIN AS PRODUCT_ID_JOIN_MTX,
  MASTER.START_DT AS START_DT_MTX,
  MASTER.END_DT AS END_DT_MTX,
  MASTER.PRODUCT_ID AS PRODUCT_ID_MTX,
  MASTER.FISCAL_MO AS FISCAL_MO_MTX,
  MASTER.BrandCd AS BRAND_CD_MTX,
  MASTER.RoyaltyFormulaCd AS MA_FORMULA_CD_MTX,
  MASTER.RoyaltyBrandDesc AS MA_EVENT_DESC_MTX,
  MASTER.RoyaltyPct1 AS MA_AMT_MTX,
  nvl(
    MASTER.Monotonically_Increasing_Id,
    DETAIL.Monotonically_Increasing_Id
  ) AS Monotonically_Increasing_Id
FROM
  FIL_Having_15 MASTER
  FULL OUTER JOIN EXP_ProductId_21 DETAIL ON MASTER.RoyaltyBrandId = DETAIL.ROYALTY_BRAND_ID
  AND MASTER.PRODUCT_ID_JOIN = DETAIL.PRODUCT_ID_JOIN
  AND MASTER.START_DT = DETAIL.START_DT
  AND MASTER.END_DT = DETAIL.END_DT""")

df_22.createOrReplaceTempView("JNR_All_22")

# COMMAND ----------
# DBTITLE 1, EXP_Strategy_23


df_23 = spark.sql("""SELECT
  IFF (ISNULL(MA_EVENT_ID), NEXTVAL, MA_EVENT_ID) AS MA_EVENT_ID,
  PRODUCT_ID_MTX AS PRODUCT_ID,
  IFF (ISNULL(START_DT), START_DT_MTX, START_DT) AS START_DT,
  IFF (ISNULL(END_DT), END_DT_MTX, END_DT) AS END_DT,
  10 AS MA_EVENT_TYPE_ID,
  9 AS MA_EVENT_SOURCE_ID,
  IFF (
    ISNULL(ROYALTY_BRAND_ID),
    ROYALTY_BRAND_ID_MTX,
    ROYALTY_BRAND_ID
  ) AS ROYALTY_BRAND_ID,
  BRAND_CD_MTX AS BRAND_CD,
  MA_FORMULA_CD_MTX AS MA_FORMULA_CD,
  IFF (ISNULL(FISCAL_MO), FISCAL_MO_MTX, FISCAL_MO) AS FISCAL_MO,
  MA_EVENT_DESC_MTX AS MA_EVENT_DESC,
  1 AS MA_PCT_IND,
  MA_AMT_MTX AS MA_AMT,
  IFF (ISNULL(UPDATE_DT), now(), UPDATE_DT) AS UPDATE_DT,
  TRUNC(now()) AS LOAD_DT,
  DECODE(
    TRUE,
    ISNULL(MA_EVENT_ID),
    'I',
    ISNULL(ROYALTY_BRAND_ID_MTX),
    'D',
    IFF(ISNULL(BRAND_CD), 'zzz ', BRAND_CD) <> IFF(ISNULL(BRAND_CD_MTX), 'zzz ', BRAND_CD_MTX)
    OR IFF(ISNULL(MA_FORMULA_CD), 'zzz ', MA_FORMULA_CD) <> IFF(
      ISNULL(MA_FORMULA_CD_MTX),
      'zzz ',
      MA_FORMULA_CD_MTX
    )
    OR IFF(ISNULL(MA_AMT), -1, MA_AMT) <> IFF(ISNULL(MA_AMT_MTX), -1, MA_AMT_MTX),
    'U',
    IFF(ISNULL(MA_EVENT_DESC), 'zzz ', MA_EVENT_DESC) <> IFF(
      ISNULL(MA_EVENT_DESC_MTX),
      'zzz ',
      MA_EVENT_DESC_MTX
    ),
    'C',
    'N'
  ) AS LOAD_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_All_22""")

df_23.createOrReplaceTempView("EXP_Strategy_23")

spark.sql("""UPDATE SEQ_MA_EVENT_ID SET CURRVAL = (SELECT MAX(in_MA_EVENT_ID) FROM EXP_Strategy_23) , NEXTVAL = (SELECT MAX(in_MA_EVENT_ID) FROM EXP_Strategy_23) + (SELECT Increment_By FROM EXP_Strategy_23)""")

# COMMAND ----------
# DBTITLE 1, FIL_LoadFlag_24


df_24 = spark.sql("""SELECT
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  LOAD_FLAG AS LOAD_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Strategy_23
WHERE
  LOAD_FLAG <> 'N'""")

df_24.createOrReplaceTempView("FIL_LoadFlag_24")

# COMMAND ----------
# DBTITLE 1, UPD_InsertDeleteUpdate_25


df_25 = spark.sql("""SELECT
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT,
  LOAD_FLAG AS Load_Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id,
  DECODE(
    TRUE,
    LOAD_FLAG = 'I',
    'DD_INSERT',
    LOAD_FLAG = 'D',
    'DD_DELETE',
    'DD_UPDATE'
  ) AS UPDATE_STRATEGY_FLAG
FROM
  FIL_LoadFlag_24""")

df_25.createOrReplaceTempView("UPD_InsertDeleteUpdate_25")

# COMMAND ----------
# DBTITLE 1, FIL_Restate_Hist_26


df_26 = spark.sql("""SELECT
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  LOAD_FLAG AS Load_Flag,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Strategy_23
WHERE
  LOAD_FLAG <> 'N'""")

df_26.createOrReplaceTempView("FIL_Restate_Hist_26")

# COMMAND ----------
# DBTITLE 1, EXP_Load_Flag_27


df_27 = spark.sql("""SELECT
  TRUNC(now()) AS LOAD_DT,
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  Load_Flag AS INS_UPD_DEL_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FIL_Restate_Hist_26""")

df_27.createOrReplaceTempView("EXP_Load_Flag_27")

# COMMAND ----------
# DBTITLE 1, UPD_InsertOnly_28


df_28 = spark.sql("""SELECT
  LOAD_DT AS LOAD_DT,
  MA_EVENT_ID AS MA_EVENT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  INS_UPD_DEL_FLAG AS INS_UPD_DEL_FLAG,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Load_Flag_27""")

df_28.createOrReplaceTempView("UPD_InsertOnly_28")

# COMMAND ----------
# DBTITLE 1, MA_EVENT


spark.sql("""MERGE INTO MA_EVENT AS TARGET
USING
  UPD_InsertDeleteUpdate_25 AS SOURCE ON TARGET.MA_EVENT_ID = SOURCE.MA_EVENT_ID
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_UPDATE" THEN
UPDATE
SET
  TARGET.MA_EVENT_ID = SOURCE.MA_EVENT_ID,
  TARGET.PRODUCT_ID = SOURCE.PRODUCT_ID,
  TARGET.START_DT = SOURCE.START_DT,
  TARGET.END_DT = SOURCE.END_DT,
  TARGET.MA_EVENT_TYPE_ID = SOURCE.MA_EVENT_TYPE_ID,
  TARGET.MA_EVENT_SOURCE_ID = SOURCE.MA_EVENT_SOURCE_ID,
  TARGET.ROYALTY_BRAND_ID = SOURCE.ROYALTY_BRAND_ID,
  TARGET.BRAND_CD = SOURCE.BRAND_CD,
  TARGET.MA_FORMULA_CD = SOURCE.MA_FORMULA_CD,
  TARGET.FISCAL_MO = SOURCE.FISCAL_MO,
  TARGET.MA_EVENT_DESC = SOURCE.MA_EVENT_DESC,
  TARGET.MA_PCT_IND = SOURCE.MA_PCT_IND,
  TARGET.MA_AMT = SOURCE.MA_AMT,
  TARGET.UPDATE_DT = SOURCE.UPDATE_DT,
  TARGET.LOAD_DT = SOURCE.LOAD_DT
  WHEN MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_DELETE"
  AND TARGET.PRODUCT_ID = SOURCE.PRODUCT_ID
  AND TARGET.START_DT = SOURCE.START_DT
  AND TARGET.END_DT = SOURCE.END_DT
  AND TARGET.MA_EVENT_TYPE_ID = SOURCE.MA_EVENT_TYPE_ID
  AND TARGET.MA_EVENT_SOURCE_ID = SOURCE.MA_EVENT_SOURCE_ID
  AND TARGET.ROYALTY_BRAND_ID = SOURCE.ROYALTY_BRAND_ID
  AND TARGET.BRAND_CD = SOURCE.BRAND_CD
  AND TARGET.MA_FORMULA_CD = SOURCE.MA_FORMULA_CD
  AND TARGET.FISCAL_MO = SOURCE.FISCAL_MO
  AND TARGET.MA_EVENT_DESC = SOURCE.MA_EVENT_DESC
  AND TARGET.MA_PCT_IND = SOURCE.MA_PCT_IND
  AND TARGET.MA_AMT = SOURCE.MA_AMT
  AND TARGET.UPDATE_DT = SOURCE.UPDATE_DT
  AND TARGET.LOAD_DT = SOURCE.LOAD_DT THEN DELETE
  WHEN NOT MATCHED
  AND SOURCE.UPDATE_STRATEGY_FLAG = "DD_INSERT" THEN
INSERT
  (
    TARGET.MA_EVENT_ID,
    TARGET.PRODUCT_ID,
    TARGET.START_DT,
    TARGET.END_DT,
    TARGET.MA_EVENT_TYPE_ID,
    TARGET.MA_EVENT_SOURCE_ID,
    TARGET.ROYALTY_BRAND_ID,
    TARGET.BRAND_CD,
    TARGET.MA_FORMULA_CD,
    TARGET.FISCAL_MO,
    TARGET.MA_EVENT_DESC,
    TARGET.MA_PCT_IND,
    TARGET.MA_AMT,
    TARGET.UPDATE_DT,
    TARGET.LOAD_DT
  )
VALUES
  (
    SOURCE.MA_EVENT_ID,
    SOURCE.PRODUCT_ID,
    SOURCE.START_DT,
    SOURCE.END_DT,
    SOURCE.MA_EVENT_TYPE_ID,
    SOURCE.MA_EVENT_SOURCE_ID,
    SOURCE.ROYALTY_BRAND_ID,
    SOURCE.BRAND_CD,
    SOURCE.MA_FORMULA_CD,
    SOURCE.FISCAL_MO,
    SOURCE.MA_EVENT_DESC,
    SOURCE.MA_PCT_IND,
    SOURCE.MA_AMT,
    SOURCE.UPDATE_DT,
    SOURCE.LOAD_DT
  )""")

# COMMAND ----------
# DBTITLE 1, MA_EVENT_RESTATE_HIST


spark.sql("""INSERT INTO
  MA_EVENT_RESTATE_HIST
SELECT
  LOAD_DT AS LOAD_DT,
  MA_EVENT_ID AS MA_EVENT_ID,
  NULL AS OFFER_ID,
  NULL AS SAP_DEPT_ID,
  PRODUCT_ID AS PRODUCT_ID,
  NULL AS COUNTRY_CD,
  START_DT AS START_DT,
  END_DT AS END_DT,
  MA_EVENT_TYPE_ID AS MA_EVENT_TYPE_ID,
  MA_EVENT_SOURCE_ID AS MA_EVENT_SOURCE_ID,
  NULL AS LOCATION_ID,
  NULL AS MOVEMENT_ID,
  NULL AS VALUATION_CLASS_CD,
  NULL AS GL_ACCT_NBR,
  NULL AS LOCATION_TYPE_ID,
  ROYALTY_BRAND_ID AS ROYALTY_BRAND_ID,
  BRAND_CD AS BRAND_CD,
  MA_FORMULA_CD AS MA_FORMULA_CD,
  FISCAL_MO AS FISCAL_MO,
  NULL AS SAP_CATEGORY_ID,
  NULL AS FROM_LOCATION_ID,
  NULL AS SOURCE_VENDOR_ID,
  NULL AS COMPANY_ID,
  MA_EVENT_DESC AS MA_EVENT_DESC,
  NULL AS EM_VENDOR_FUNDING_ID,
  NULL AS EM_COMMENT,
  NULL AS EM_BILL_ALT_VENDOR_FLAG,
  NULL AS EM_ALT_VENDOR_ID,
  NULL AS EM_ALT_VENDOR_NAME,
  NULL AS EM_ALT_VENDOR_COUNTRY_CD,
  NULL AS EM_VENDOR_ID,
  NULL AS EM_VENDOR_NAME,
  NULL AS EM_VENDOR_COUNTRY_CD,
  NULL AS VENDOR_NAME_TXT,
  MA_PCT_IND AS MA_PCT_IND,
  MA_AMT AS MA_AMT,
  NULL AS MA_MAX_AMT,
  INS_UPD_DEL_FLAG AS INS_UPD_DEL_FLAG FROMUPD_InsertOnly_28""")